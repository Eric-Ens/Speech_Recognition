{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A second method for changing the data\n",
    "****\n",
    "We will attempt a second method of changing the data used by https://www.kaggle.com/kcs93023/tf-speech-recognition-by-cnn\n",
    "\n",
    "This translates the data into numpy arrays directly. It will be possible to build the model directly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#Scientific Library\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "#import plotly.offline as py\n",
    "#py.init_notebook_mode(connected=True)\n",
    "#import plotly.graph_objs as go\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Preliminary_CNN.ipynb', '.DS_Store', 'test', 'Convert_to_Spec.ipynb', 'specs', 'specs_split', 'README.md', 'train', '.ipynb_checkpoints', '.git', 'Data_spec_pt_2.ipynb']\n",
      "['right', 'eight', 'cat', 'tree', 'bed', 'happy', 'go', 'dog', 'no', 'wow', 'nine', 'left', 'stop', 'three', '_background_noise_', 'sheila', 'one', 'bird', 'zero', 'seven', 'up', 'marvin', 'two', 'house', 'down', 'six', 'yes', 'on', 'five', 'off', 'four']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../Speech_Recognition/\"))\n",
    "audio_path = '../Speech_Recognition/train/audio/'\n",
    "print(os.listdir(audio_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20, step_size = 10,\n",
    "                eps = 1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                           fs = sample_rate,\n",
    "                                           window='hann',\n",
    "                                           nperseg = nperseg,\n",
    "                                           noverlap=noverlap,\n",
    "                                           detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "dirs = [f for f in os.listdir(audio_path) if isdir(join(audio_path, f))]\n",
    "dirs.sort()\n",
    "\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Eric/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n",
      "/Users/Eric/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "spec_all = []\n",
    "target_all = []\n",
    "target_value = {}\n",
    "\n",
    "for i, direct in enumerate(dirs):\n",
    "    # read wave files each directory\n",
    "    waves = [f for f in os.listdir(join(audio_path, direct)) if f.endswith('.wav')]\n",
    "    target_value[direct] = i\n",
    "    for j, wav in enumerate(waves):\n",
    "        target_all.append(direct)\n",
    "        sample_rate, samples = wavfile.read(join(audio_path, direct, wav))\n",
    "        #Resample\n",
    "        if samples.shape[0] != 16000 :\n",
    "            continue;\n",
    "#         resamples = signal.resample(samples, new_sample_rate)\n",
    "        freqs, times, spec = log_specgram(samples, sample_rate)\n",
    "        # min-max Normalization\n",
    "        spec = (spec - spec.min())/(spec.max() - spec.min())\n",
    "     \n",
    "        all_data.append([spec.T, direct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "np.random.shuffle(all_data)\n",
    "# split data to Spectrogram and Label\n",
    "spec_all = np.reshape(np.delete(all_data,1,1),(len(all_data)))\n",
    "target_all = [i for i in np.delete(all_data,0,1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 80% train indices \n",
    "train_indices = np.random.choice(len(target_all),\n",
    "                                 round(len(target_all) * 0.8), replace=False)\n",
    "# get 20% test indices without train indices\n",
    "test_indices = np.array(list(set(range(len(target_all)))\n",
    "                                 - set(train_indices)))\n",
    "# Arrangement\n",
    "spec_vals = np.array([x for x in spec_all])\n",
    "target_vals = np.array([x for x in target_all])\n",
    "\n",
    "# split data train and test\n",
    "train_spec = spec_vals[train_indices][:]\n",
    "train_target = target_vals[train_indices][:]\n",
    "test_spec = spec_vals[test_indices][:]\n",
    "test_target = target_vals[test_indices][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78473073, 0.6655199 , 0.7712438 , ..., 0.7938667 , 0.7821201 ,\n",
       "        0.7791913 ],\n",
       "       [0.78149277, 0.7461919 , 0.7597199 , ..., 0.77292025, 0.7490061 ,\n",
       "        0.7811874 ],\n",
       "       [0.6986473 , 0.6939601 , 0.7037581 , ..., 0.6874292 , 0.6938926 ,\n",
       "        0.72256225],\n",
       "       ...,\n",
       "       [0.31088853, 0.3300051 , 0.24489383, ..., 0.26862344, 0.3622802 ,\n",
       "        0.3643632 ],\n",
       "       [0.28287166, 0.28495398, 0.26801312, ..., 0.2821961 , 0.22291708,\n",
       "        0.33880827],\n",
       "       [0.2537828 , 0.18082158, 0.29916936, ..., 0.3052732 , 0.25261372,\n",
       "        0.3096    ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
