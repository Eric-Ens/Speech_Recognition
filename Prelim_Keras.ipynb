{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model\n",
    "****\n",
    "The model in premiliminary CNN we can try to build with Keras. Keras will enable us to drop the unknown class, and instead let the model decide on a 'none-of-the-above' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import resample\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "#import keras\n",
    "#from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "#from keras.models import Sequential\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.optimizers import SGD\n",
    "#from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up constants\n",
    "****\n",
    "First we will set up our constants and filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 7         # Convolution filters are 13x13 pixels.\n",
    "num_filters1 = 56         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 7         # Convolution filters are 13x13 pixels.\n",
    "num_filters2 = 112         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 512             # Number of neurons in fully-connected layer.\n",
    "fc_size_2 = 256\n",
    "\n",
    "# The number of pixels in each dimension of an image.\n",
    "img_height = 128 # 161 for spectrogram, 128 for mfcc\n",
    "img_width = 32 # 99 for spec, 32 for mfcc\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_height * img_width\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (128,32) #(161,99) for spec possibly reverse x and y\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 12\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "****\n",
    "Like in the previous model, we will load the data first as filenames into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_\") # for file types add '.+(type)'\n",
    "    all_files = glob(os.path.join(data_dir, 'mfcc/train/*/*')) # for file types at (type)\n",
    "                                                            # file path csv for 1sec exactly, and csv_full\n",
    "                                                            # for all file\n",
    "                                                            # for mfcc use mfcc/\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_clips = fin.readlines()\n",
    "        validation_files = [x[:-3] for x in validation_clips] # for file types at \"+'(type)'\" to [:-3]\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "            label_vec = np.eye(len(id2name))[label_id]\n",
    "\n",
    "            sample = (label, label_id, label_vec, uid, entry)\n",
    "            if uid in valset:\n",
    "                #if # only include val set that is precisely 1 sec\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    \n",
    "    columns_list = ['label', 'label_id', 'label_vec', 'user_id', 'file_name']\n",
    "    \n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    \n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57923 train and 6798 val samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_vec</th>\n",
       "      <th>user_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9190045a</td>\n",
       "      <td>mfcc/train/right/9190045a_nohash_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>a6d586b7</td>\n",
       "      <td>mfcc/train/right/a6d586b7_nohash_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>dca2797e</td>\n",
       "      <td>mfcc/train/right/dca2797e_nohash_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>538e1856</td>\n",
       "      <td>mfcc/train/right/538e1856_nohash_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>a6d586b7</td>\n",
       "      <td>mfcc/train/right/a6d586b7_nohash_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  label_id                                          label_vec  \\\n",
       "0  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "2  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "3  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "4  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "    user_id                           file_name  \n",
       "0  9190045a  mfcc/train/right/9190045a_nohash_0  \n",
       "1  a6d586b7  mfcc/train/right/a6d586b7_nohash_4  \n",
       "2  dca2797e  mfcc/train/right/dca2797e_nohash_4  \n",
       "3  538e1856  mfcc/train/right/538e1856_nohash_0  \n",
       "4  a6d586b7  mfcc/train/right/a6d586b7_nohash_3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, valid_df = load_data('')\n",
    "imp_cols = ['label','label_vec','user_id','file_name']\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will reduce the unknown class, the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_vec</th>\n",
       "      <th>user_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38923</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1625acd8</td>\n",
       "      <td>mfcc/train/marvin/1625acd8_nohash_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53094</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9aa5439d</td>\n",
       "      <td>mfcc/train/five/9aa5439d_nohash_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19083</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>60472d26</td>\n",
       "      <td>mfcc/train/nine/60472d26_nohash_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>44dad20e</td>\n",
       "      <td>mfcc/train/happy/44dad20e_nohash_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57029</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>937b433e</td>\n",
       "      <td>mfcc/train/four/937b433e_nohash_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  label_id                                          label_vec  \\\n",
       "38923  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "53094  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "19083  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "10120  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "57029  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "        user_id                            file_name  \n",
       "38923  1625acd8  mfcc/train/marvin/1625acd8_nohash_1  \n",
       "53094  9aa5439d    mfcc/train/five/9aa5439d_nohash_2  \n",
       "19083  60472d26    mfcc/train/nine/60472d26_nohash_1  \n",
       "10120  44dad20e   mfcc/train/happy/44dad20e_nohash_1  \n",
       "57029  937b433e    mfcc/train/four/937b433e_nohash_0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_size = np.int(train_df[train_df['label_id'] != 11]['label_id'].value_counts().mean())\n",
    "df_maj = train_df[train_df['label_id'] == 11]\n",
    "df_rest = train_df[train_df['label_id'] != 11]\n",
    "columns_list = ['label_id', 'label', 'label_vec', 'user_id', 'file_name']\n",
    "\n",
    "df_majority_downsampled = resample(df_maj, \n",
    "                                   replace=False,    # sample without replacement\n",
    "                                   n_samples=avg_size,     # to match minority class\n",
    "                                   random_state=5)\n",
    "\n",
    "train_DS = pd.concat([df_majority_downsampled, df_rest])\n",
    "train_DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     2134\n",
       "0     2116\n",
       "2     2115\n",
       "9     2112\n",
       "5     2111\n",
       "11    2110\n",
       "6     2110\n",
       "4     2106\n",
       "1     2105\n",
       "7     2101\n",
       "3     2095\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DS['label_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_vec</th>\n",
       "      <th>user_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32969</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1fe4c891</td>\n",
       "      <td>mfcc/train/zero/1fe4c891_nohash_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14154</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>c93d5e22</td>\n",
       "      <td>mfcc/train/no/c93d5e22_nohash_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>stop</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>c33682f0</td>\n",
       "      <td>mfcc/train/stop/c33682f0_nohash_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51332</th>\n",
       "      <td>on</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>a3255f5c</td>\n",
       "      <td>mfcc/train/on/a3255f5c_nohash_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48221</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>c103a2d5</td>\n",
       "      <td>mfcc/train/yes/c103a2d5_nohash_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36917</th>\n",
       "      <td>up</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>eb76bc68</td>\n",
       "      <td>mfcc/train/up/eb76bc68_nohash_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22406</th>\n",
       "      <td>stop</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>ec201020</td>\n",
       "      <td>mfcc/train/stop/ec201020_nohash_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51012</th>\n",
       "      <td>on</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>d90b4138</td>\n",
       "      <td>mfcc/train/on/d90b4138_nohash_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24056</th>\n",
       "      <td>stop</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>98447c43</td>\n",
       "      <td>mfcc/train/stop/98447c43_nohash_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25880</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>aff582a1</td>\n",
       "      <td>mfcc/train/three/aff582a1_nohash_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  label_id                                          label_vec  \\\n",
       "32969  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "14154       no         1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "22539     stop         8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "51332       on         6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "48221      yes         0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "36917       up         2  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "22406     stop         8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "51012       on         6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "24056     stop         8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "25880  unknown        11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "        user_id                           file_name  \n",
       "32969  1fe4c891   mfcc/train/zero/1fe4c891_nohash_0  \n",
       "14154  c93d5e22     mfcc/train/no/c93d5e22_nohash_4  \n",
       "22539  c33682f0   mfcc/train/stop/c33682f0_nohash_0  \n",
       "51332  a3255f5c     mfcc/train/on/a3255f5c_nohash_0  \n",
       "48221  c103a2d5    mfcc/train/yes/c103a2d5_nohash_1  \n",
       "36917  eb76bc68     mfcc/train/up/eb76bc68_nohash_1  \n",
       "22406  ec201020   mfcc/train/stop/ec201020_nohash_3  \n",
       "51012  d90b4138     mfcc/train/on/d90b4138_nohash_2  \n",
       "24056  98447c43   mfcc/train/stop/98447c43_nohash_1  \n",
       "25880  aff582a1  mfcc/train/three/aff582a1_nohash_0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_mini = train_DS.sample(10)\n",
    "valid_df_mini = valid_df.sample(10)\n",
    "train_df_mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Ready for Keras\n",
    "****\n",
    "using the template from https://github.com/spmallick/learnopencv/blob/master/KerasCNN-CIFAR/keras-cnn-cifar10.ipynb\n",
    "I want to make sure everything fits right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  11\n",
      "Output classes :  ['unknown' 'right' 'go' 'no' 'left' 'stop' 'up' 'down' 'yes' 'on' 'off']\n"
     ]
    }
   ],
   "source": [
    "#print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    "\n",
    "#print('Testing data shape : ', test_images.shape, test_labels.shape)\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = train_DS['label'].unique()#np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4096)\n",
      "[[0.09953697 0.04183185 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.36989701 0.30088534 0.26672063 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.15030131 0.14289246 0.02976772 ... 0.         0.         0.        ]\n",
      " [0.41232392 0.41378406 0.43046774 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Find the shape of input images and create the variable input_shape\n",
    "nRows,nCols,nDims = img_height, img_width, num_channels\n",
    "input_shape = (nRows, nCols, nDims)\n",
    "\n",
    "# Change to float datatype\n",
    "#train_data = train_data.astype('float32')\n",
    "#test_data = test_data.astype('float32')\n",
    "\n",
    "# Change the labels from integer to categorical data\n",
    "#train_labels_one_hot = to_categorical(train_labels)\n",
    "#test_labels_one_hot = to_categorical(test_labels)\n",
    "\n",
    "train_data = np.array([pd.read_csv(x, sep=',',header=None).T.values.tolist()[0] for x in train_DS['file_name']])\n",
    "train_labels_one_hot = np.array([y for y in train_DS['label_vec']])\n",
    "\n",
    "test_data = np.array([pd.read_csv(x, sep=',',header=None).T.values.tolist()[0] for x in valid_df['file_name']])\n",
    "test_labels_one_hot = np.array([y for y in valid_df['label_vec']])\n",
    "\n",
    "train_mini = np.array([pd.read_csv(x, sep=',',header=None).T.values.tolist()[0] \n",
    "                       for x in train_df_mini['file_name']])\n",
    "train_labels_mini = np.array([y for y in train_df_mini['label_vec']])\n",
    "\n",
    "test_mini = np.array([pd.read_csv(x, sep=',',header=None).T.values.tolist()[0] \n",
    "                      for x in valid_df_mini['file_name']])\n",
    "test_labels_mini = np.array([y for y in valid_df_mini['label_vec']])\n",
    "print(train_mini.shape)\n",
    "print(train_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "train_mini_rs = train_mini.reshape(train_mini.shape[0], nRows, nCols, nDims)\n",
    "print(train_mini_rs.shape)\n",
    "#print(train_mini_rs)\n",
    "\n",
    "valid_mini_rs = test_mini.reshape(test_mini.shape[0], nRows, nCols, nDims)\n",
    "train_data_rs = train_data.reshape(train_data.shape[0], nRows, nCols, nDims)\n",
    "test_data_rs = test_data.reshape(test_data[0], nRows, nCols, nDims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model\n",
    "****\n",
    "Now we will build our Keras model using the same architecture as the tensorflow one. In tensorflow, we found we were able to exceed 78%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential()\n",
    "    # The first two layers with 32 filters of window size 3x3\n",
    "    model.add(Conv2D(num_filters1, (filter_size1, filter_size1), \n",
    "                     padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(num_filters2, (filter_size2, filter_size2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(fc_size, activation='relu'))\n",
    "    model.add(Dense(fc_size_2, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = createModel()\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "model1.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "############\n",
    "\n",
    "history = model1.fit(train_data_rs, train_labels_one_hot, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                   validation_data=(test_data_rs, test_labels_one_hot))\n",
    "model1.evaluate(test_data_rs, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
