{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor Model\n",
    "****\n",
    "In the notebook 11_class_CNN we trained a CNN to recognize spoken words and it performed well enough. In this notebook we will be re-creating that model in order to train it on all of the data in the training set without seperating a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from datetime import timedelta\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 6         # number of pixels in one side of the filter\n",
    "num_filters1 = 72         # number of filters\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 6\n",
    "num_filters2 = 112\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 256             # Number of neurons in fully-connected layer.\n",
    "fc_size_2 = 256\n",
    "\n",
    "# The number of pixels in each dimension of an image.\n",
    "img_height = 128 # 161 for spec, 128 for mfcc\n",
    "img_width = 32 #99 for spec 32 for mfcc\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_height * img_width\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (128, 32)# (161,99)\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 12\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "#The file path for the original audio files\n",
    "audio_path = 'train/audio/'\n",
    "test_path = 'test/'\n",
    "\n",
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_\") # for file types add '.+(type)'\n",
    "    all_files = glob(os.path.join(data_dir, 'mfcc/train/*/*'))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train = []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label = r.group(2)\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "            label_vec = np.eye(len(id2name))[label_id]\n",
    "            sound_path = audio_path + \"/\".join(entry.strip(\"/\").split('/')[2:]) + '.wav'#str(entry)\n",
    "\n",
    "            sample = (label, label_id, label_vec, entry, sound_path)\n",
    "            train.append(sample)\n",
    "\n",
    "    columns_list = ['label', 'label_id', 'label_vec', 'file_name', 'audio_file']\n",
    "    \n",
    "    return pd.DataFrame(train, columns = columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_vec</th>\n",
       "      <th>file_name</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mfcc/train/right/3bfd30e6_nohash_2</td>\n",
       "      <td>train/audio/right/3bfd30e6_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mfcc/train/right/9190045a_nohash_0</td>\n",
       "      <td>train/audio/right/9190045a_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mfcc/train/right/dabf67d9_nohash_0</td>\n",
       "      <td>train/audio/right/dabf67d9_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mfcc/train/right/b7a0754f_nohash_0</td>\n",
       "      <td>train/audio/right/b7a0754f_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mfcc/train/right/a1cff772_nohash_2</td>\n",
       "      <td>train/audio/right/a1cff772_nohash_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  label_id                                          label_vec  \\\n",
       "0  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "2  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "3  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "4  right         5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            file_name                               audio_file  \n",
       "0  mfcc/train/right/3bfd30e6_nohash_2  train/audio/right/3bfd30e6_nohash_2.wav  \n",
       "1  mfcc/train/right/9190045a_nohash_0  train/audio/right/9190045a_nohash_0.wav  \n",
       "2  mfcc/train/right/dabf67d9_nohash_0  train/audio/right/dabf67d9_nohash_0.wav  \n",
       "3  mfcc/train/right/b7a0754f_nohash_0  train/audio/right/b7a0754f_nohash_0.wav  \n",
       "4  mfcc/train/right/a1cff772_nohash_2  train/audio/right/a1cff772_nohash_2.wav  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = load_data('')\n",
    "label_df = train_df[['label','label_id']].drop_duplicates(\n",
    "    subset=None, keep='first', inplace=False).set_index('label_id')\n",
    "label_names = label_df['label'].sort_index()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     2380\n",
       "0     2377\n",
       "2     2375\n",
       "1     2375\n",
       "9     2372\n",
       "11    2368\n",
       "10    2368\n",
       "6     2367\n",
       "5     2367\n",
       "3     2359\n",
       "7     2357\n",
       "4     2353\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_size = np.int(train_df[train_df['label_id'] < 10]['label_id'].value_counts().mean())\n",
    "df_maj = train_df[train_df['label_id'] == 11]\n",
    "df_min = train_df[train_df['label_id'] == 10]\n",
    "df_rest = train_df[train_df['label_id'] < 10]\n",
    "\n",
    "df_majority_downsampled = resample(df_maj, replace=False, n_samples=avg_size, random_state=5)\n",
    "\n",
    "df_minority_upsampled = resample(df_min, n_samples = avg_size, random_state=5)\n",
    "\n",
    "train_DS = pd.concat([df_majority_downsampled, df_minority_upsampled, df_rest])\n",
    "train_DS['label_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNN\n",
    "****\n",
    "We will leave out the info stuff like sound files, etc and get straight to rebuilding the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape=shape)\n",
    "    biases = new_biases(length=num_filters)\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "    layer += biases\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer, weights\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_height, img_width, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "keep_prob_1 = tf.placeholder(tf.float32)\n",
    "keep_prob_2 = tf.placeholder(tf.float32)\n",
    "keep_prob_3 = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                            use_pooling=True)\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,\n",
    "                                            num_input_channels=num_filters1,\n",
    "                                            filter_size=filter_size2,\n",
    "                                            num_filters=num_filters2,\n",
    "                                            use_pooling=True)\n",
    "layer_flat, num_features = flatten_layer(layer_conv2)\n",
    "\n",
    "dropout_1 = tf.nn.dropout(layer_flat, keep_prob_1)\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=dropout_1,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "dropout_2 = tf.nn.dropout(layer_fc1, keep_prob_2)\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size_2,\n",
    "                         use_relu=True)\n",
    "\n",
    "dropout_3 = tf.nn.dropout(layer_fc2, keep_prob_3)\n",
    "\n",
    "layer_fc3 = new_fc_layer(input=dropout_2,\n",
    "                         num_inputs=fc_size_2,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc3)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-32d129351efa>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc3, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = 'Run 1 with 2 conv layers'\n",
    "\n",
    "training_writer = tf.summary.FileWriter(\"./logs/{}/training\".format(RUN_NAME), session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 50\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        \n",
    "        batch_df = train_DS.sample(train_batch_size)\n",
    "        x_batch = np.array(\n",
    "            [pd.read_csv(x, sep=',',header=None).T.values.tolist()[0] for x in batch_df['file_name']])\n",
    "        y_true_batch = np.array([y for y in batch_df['label_vec']])\n",
    "        \n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch,\n",
    "                           keep_prob_1: 0.5, keep_prob_2: 0.5, keep_prob_3: 0.5}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   6.0%\n",
      "Optimization Iteration:   1001, Training Accuracy:  66.0%\n",
      "Time usage: 0:31:19\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2001, Training Accuracy:  76.0%\n",
      "Optimization Iteration:   3001, Training Accuracy:  76.0%\n",
      "Optimization Iteration:   4001, Training Accuracy:  78.0%\n",
      "Time usage: 0:46:47\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5001, Training Accuracy:  82.0%\n",
      "Optimization Iteration:   6001, Training Accuracy:  82.0%\n",
      "Optimization Iteration:   7001, Training Accuracy:  94.0%\n",
      "Optimization Iteration:   8001, Training Accuracy:  92.0%\n",
      "Optimization Iteration:   9001, Training Accuracy:  94.0%\n",
      "Time usage: 1:16:52\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize(num_iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(data_dir):\n",
    "    all_files = glob(os.path.join(data_dir, 'mfcc/test/*'))\n",
    "    test = []\n",
    "    for entry in all_files:\n",
    "        sound_path = test_path + \"/\".join(entry.split('/')[1:]) + '.wav'\n",
    "        sample = (entry, sound_path)\n",
    "        test.append(sample)\n",
    "            \n",
    "    columns_list = ['file_name', 'audio_file']\n",
    "    test_df = pd.DataFrame(test, columns = columns_list)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mfcc/test/clip_e5079a5ec</td>\n",
       "      <td>test/test/clip_e5079a5ec.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mfcc/test/clip_9b6cb90e7</td>\n",
       "      <td>test/test/clip_9b6cb90e7.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mfcc/test/clip_2e6d2f181</td>\n",
       "      <td>test/test/clip_2e6d2f181.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mfcc/test/clip_e75d514f3</td>\n",
       "      <td>test/test/clip_e75d514f3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mfcc/test/clip_c5db7ac41</td>\n",
       "      <td>test/test/clip_c5db7ac41.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name                    audio_file\n",
       "0  mfcc/test/clip_e5079a5ec  test/test/clip_e5079a5ec.wav\n",
       "1  mfcc/test/clip_9b6cb90e7  test/test/clip_9b6cb90e7.wav\n",
       "2  mfcc/test/clip_2e6d2f181  test/test/clip_2e6d2f181.wav\n",
       "3  mfcc/test/clip_e75d514f3  test/test/clip_e75d514f3.wav\n",
       "4  mfcc/test/clip_c5db7ac41  test/test/clip_c5db7ac41.wav"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kaggle_test = load_test('')\n",
    "Kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_files(test_batch_size = 256):\n",
    "    num_test = len(Kaggle_test)\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    names_pred = np.empty(shape=num_test, dtype=str)\n",
    "\n",
    "    i = 0\n",
    "    x_test_array = np.array([pd.read_csv(x, sep=',', header=None).T.values.tolist()[0] \n",
    "                             for x in Kaggle_test['file_name']])\n",
    "    x_test_files = np.array([x.split('/')[-1] for x in Kaggle_test['audio_file']])\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        files = x_test_array[i:j, :]\n",
    "        feed_dict = {x: files, keep_prob_1: 1, keep_prob_2: 1, keep_prob_3: 1}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        names_pred[i:j] = x_test_files[i:j]\n",
    "        i = j\n",
    "\n",
    "    return x_test_files, cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, file_predictions = predict_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fname</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clip_e5079a5ec.wav</th>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_9b6cb90e7.wav</th>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_2e6d2f181.wav</th>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_e75d514f3.wav</th>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_c5db7ac41.wav</th>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label\n",
       "fname                      \n",
       "clip_e5079a5ec.wav  unknown\n",
       "clip_9b6cb90e7.wav     down\n",
       "clip_2e6d2f181.wav  unknown\n",
       "clip_e75d514f3.wav  silence\n",
       "clip_c5db7ac41.wav  unknown"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_kaggle = ['fname']\n",
    "kaggle_df = pd.DataFrame(file_names, columns = columns_kaggle)\n",
    "kaggle_df['label'] = pd.Series(file_predictions)\n",
    "kaggle_df = kaggle_df.replace({\"label\": id2name})\n",
    "kaggle_df = kaggle_df.set_index('fname')\n",
    "kaggle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv('Kaggle_Predictions_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
